import { ServicesAccessor } from '../../../../../../util/vs/platform/instantiation/common/instantiation';
import { TelemetryWithExp } from '../telemetry';
import { ICompletionsRuntimeModeService } from '../util/runtimeMode';
import { CopilotNamedAnnotationList } from './stream';
export { FinishedCallback, getRequestId } from './fetch';
export interface RequestId {
    headerRequestId: string;
    serverExperiments: string;
    deploymentId: string;
}
export interface APIChoice {
    completionText: string;
    meanLogProb: number | undefined;
    meanAlternativeLogProb: number | undefined;
    choiceIndex: number;
    requestId: RequestId;
    tokens: string[];
    numTokens: number;
    blockFinished: boolean;
    telemetryData: TelemetryWithExp;
    copilotAnnotations?: CopilotNamedAnnotationList;
    clientCompletionId: string;
    finishReason: string;
    generatedChoiceIndex?: number;
}
/** How the logprobs field looks in the OpenAI API chunks. */
export interface APILogprobs {
    text_offset: number[];
    token_logprobs: number[];
    top_logprobs?: {
        [key: string]: number;
    }[];
    tokens: string[];
}
export interface APIJsonData {
    text: string;
    tokens: string[];
    logprobs?: APILogprobs;
    copilot_annotations?: CopilotNamedAnnotationList;
    finish_reason: string;
}
export declare function convertToAPIChoice(accessor: ServicesAccessor, completionText: string, jsonData: APIJsonData, choiceIndex: number, requestId: RequestId, blockFinished: boolean, telemetryData: TelemetryWithExp): APIChoice;
export declare function getTemperatureForSamples(runtime: ICompletionsRuntimeModeService, numShots: number): number;
export declare function getStops(languageId?: string): string[];
export declare function getTopP(): number;
export declare function getMaxSolutionTokens(): number;
//# sourceMappingURL=openai.d.ts.map